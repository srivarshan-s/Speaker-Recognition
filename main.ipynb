{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIO-9dZpMKmN"
      },
      "source": [
        "## Environment Setup"
      ],
      "id": "EIO-9dZpMKmN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IRnf6dbMNE7",
        "outputId": "3a1a5a91-a335-4ea9-9079-407de80819be"
      },
      "source": [
        "! git clone https://github.com/srivarshan-s/Speaker-Recognition.git\n",
        "% cd Speaker-Recognition"
      ],
      "id": "8IRnf6dbMNE7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Speaker-Recognition'...\n",
            "remote: Enumerating objects: 5315, done.\u001b[K\n",
            "remote: Counting objects: 100% (5315/5315), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5284/5284), done.\u001b[K\n",
            "remote: Total 5315 (delta 33), reused 5306 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (5315/5315), 36.36 MiB | 12.97 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "/content/Speaker-Recognition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c057a6d-f42f-4791-b8a5-db8fb37839c0"
      },
      "source": [
        "## Importing Libraries"
      ],
      "id": "9c057a6d-f42f-4791-b8a5-db8fb37839c0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b21202db-4861-44ed-9adf-7aa5e3376b27"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "id": "b21202db-4861-44ed-9adf-7aa5e3376b27",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07a445fe-a062-4cc5-9a23-1e34d002447a"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "id": "07a445fe-a062-4cc5-9a23-1e34d002447a",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02c4776c-30c7-4388-9c1f-bd3f7344ad01"
      },
      "source": [
        "import os\n",
        "os. environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ],
      "id": "02c4776c-30c7-4388-9c1f-bd3f7344ad01",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee9f67ab-011e-42bf-ae97-edf7f792a526"
      },
      "source": [
        "## Loading Data"
      ],
      "id": "ee9f67ab-011e-42bf-ae97-edf7f792a526"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "758e8b79-2c16-4148-a237-5b7bd7e14044"
      },
      "source": [
        "SEED = 2017\n",
        "DATA_DIR = 'data/' "
      ],
      "id": "758e8b79-2c16-4148-a237-5b7bd7e14044",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb4bb137-bbae-4783-bb92-b0768c60cec6"
      },
      "source": [
        "files = glob.glob(DATA_DIR + \"*.wav\")\n",
        "X_train, X_val = train_test_split(files, test_size=0.2, random_state=SEED)"
      ],
      "id": "fb4bb137-bbae-4783-bb92-b0768c60cec6",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdd473ca-623e-4649-b524-5ec7f81a91cd",
        "outputId": "80a95d42-605c-4154-80ac-0ed03e5ad153"
      },
      "source": [
        "print('Training examples: {}'.format(len(X_train)))\n",
        "print('Validation examples: {}'.format(len(X_val)))"
      ],
      "id": "bdd473ca-623e-4649-b524-5ec7f81a91cd",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: 1920\n",
            "Validation examples: 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08dea5c0-8b38-472e-9312-e54ccf8aec20"
      },
      "source": [
        "labels = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    label = X_train[i].split('/')[-1].split('_')[1]\n",
        "    \n",
        "    if label not in labels:\n",
        "        labels.append(label)"
      ],
      "id": "08dea5c0-8b38-472e-9312-e54ccf8aec20",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44c51831-2b70-4c83-93f0-951338e2a682",
        "outputId": "ae62a639-4d01-4376-e512-bf3669202fc9"
      },
      "source": [
        "print(labels)"
      ],
      "id": "44c51831-2b70-4c83-93f0-951338e2a682",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Junior', 'Daniel', 'Steffi', 'Victoria', 'Tom', 'Samantha', 'Princess', 'Ralph', 'Alex', 'Kathy', 'Agnes', 'Bruce', 'Albert', 'Fred', 'Vicki']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4823e37b-1bbc-4a62-8c18-daeac8e713a4"
      },
      "source": [
        "## Data Preprocessing"
      ],
      "id": "4823e37b-1bbc-4a62-8c18-daeac8e713a4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71169dc6-b450-48c8-9347-adacd419ae9c",
        "outputId": "1d63e1e2-b354-43c1-9658-ccb39f12b471"
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "label_binarizer.fit(list(set(labels)))"
      ],
      "id": "71169dc6-b450-48c8-9347-adacd419ae9c",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelBinarizer()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da3cd7b3-bcd7-43c0-ab2f-d3b5c70a4afd"
      },
      "source": [
        "def one_hot_encode(label):\n",
        "    return label_binarizer.transform(label)"
      ],
      "id": "da3cd7b3-bcd7-43c0-ab2f-d3b5c70a4afd",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6411f8c9-ed0b-4b6d-b6a8-4d2aef0c666e"
      },
      "source": [
        "n_features = 20\n",
        "max_length = 80\n",
        "n_classes = len(labels)"
      ],
      "id": "6411f8c9-ed0b-4b6d-b6a8-4d2aef0c666e",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bb862de-a36b-47ec-8852-85f7a77475b2"
      },
      "source": [
        "def batch_generator(data, batch_size=16):\n",
        "    while 1:\n",
        "        random.shuffle(data)\n",
        "        X, y = [], []\n",
        "        for i in range(batch_size):\n",
        "            wav = data[i]\n",
        "            wave, sr = librosa.load(wav, mono=True)\n",
        "            label = wav.split('/')[-1].split('_')[1]\n",
        "            y.append(label)\n",
        "            mfcc = librosa.feature.mfcc(wave, sr)\n",
        "            mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0) \n",
        "            X.append(np.array(mfcc))\n",
        "        yield np.array(X), np.array(one_hot_encode(y))"
      ],
      "id": "3bb862de-a36b-47ec-8852-85f7a77475b2",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "232cae79-f33d-437c-b7c3-663c123b87da"
      },
      "source": [
        "## Model Training"
      ],
      "id": "232cae79-f33d-437c-b7c3-663c123b87da"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b907933f-d179-4894-90eb-e0947bdeea0e"
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "n_epochs = 50\n",
        "dropout = 0.5"
      ],
      "id": "b907933f-d179-4894-90eb-e0947bdeea0e",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775c8232-ed21-42fc-98e3-177c61c00607"
      },
      "source": [
        "input_shape = (n_features, max_length)\n",
        "steps_per_epoch = 50"
      ],
      "id": "775c8232-ed21-42fc-98e3-177c61c00607",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a21d2fc4-b3e0-4abc-8aaa-3520f526db78"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, return_sequences=True, input_shape=input_shape,\n",
        "dropout=dropout))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(n_classes, activation='softmax'))"
      ],
      "id": "a21d2fc4-b3e0-4abc-8aaa-3520f526db78",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3d822c4-ed8e-40d3-b81d-fd100c05d520",
        "outputId": "13e96b60-4168-421c-e4c1-94672f52f02a"
      },
      "source": [
        "opt = Adam(learning_rate=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "id": "f3d822c4-ed8e-40d3-b81d-fd100c05d520",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 20, 256)           345088    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5120)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               655488    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,002,511\n",
            "Trainable params: 1,002,511\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70be77c1-ab92-4dea-a4f0-8b7f43d8ac4f"
      },
      "source": [
        "callbacks = [ModelCheckpoint('checkpoints/voice_recognition_best_model_{epoch:02d}.hdf5', save_best_only=True),\n",
        "            EarlyStopping(monitor='val_accuracy', patience=2)]"
      ],
      "id": "70be77c1-ab92-4dea-a4f0-8b7f43d8ac4f",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "671dea65-c56e-4002-b8f5-d8e992bcc61e",
        "outputId": "dfdcd2a1-00c6-47c9-a330-8a2bd46ff0f9"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    generator=batch_generator(X_train, batch_size),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=n_epochs,\n",
        "    verbose=1,\n",
        "    validation_data=batch_generator(X_val, 32),\n",
        "    validation_steps=5,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "id": "671dea65-c56e-4002-b8f5-d8e992bcc61e",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "50/50 [==============================] - 94s 2s/step - loss: 2.4039 - accuracy: 0.2138 - val_loss: 1.8423 - val_accuracy: 0.3812\n",
            "Epoch 2/50\n",
            "50/50 [==============================] - 90s 2s/step - loss: 1.7808 - accuracy: 0.4038 - val_loss: 1.3632 - val_accuracy: 0.5125\n",
            "Epoch 3/50\n",
            "50/50 [==============================] - 91s 2s/step - loss: 1.4401 - accuracy: 0.5119 - val_loss: 0.9730 - val_accuracy: 0.6250\n",
            "Epoch 4/50\n",
            "50/50 [==============================] - 92s 2s/step - loss: 1.2184 - accuracy: 0.5806 - val_loss: 0.6475 - val_accuracy: 0.8250\n",
            "Epoch 5/50\n",
            "50/50 [==============================] - 91s 2s/step - loss: 1.0364 - accuracy: 0.6484 - val_loss: 0.5268 - val_accuracy: 0.7812\n",
            "Epoch 6/50\n",
            "50/50 [==============================] - 90s 2s/step - loss: 0.8977 - accuracy: 0.6928 - val_loss: 0.5585 - val_accuracy: 0.8250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JzhJqDnVZid"
      },
      "source": [
        "## Load the Model from Checkpoints"
      ],
      "id": "7JzhJqDnVZid"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp92qZfSe-vw"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, return_sequences=True, input_shape=input_shape,\n",
        "dropout=dropout))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "opt = Adam(learning_rate=learning_rate)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "id": "zp92qZfSe-vw",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flKQbCjYWJ5W"
      },
      "source": [
        "model.load_weights('checkpoints/voice_recognition_best_model_12.hdf5')"
      ],
      "id": "flKQbCjYWJ5W",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCRQZGEZWyrx"
      },
      "source": [
        "## Perform Speaker Recognition"
      ],
      "id": "iCRQZGEZWyrx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXlenB9BWTkk"
      },
      "source": [
        "wave, sr = librosa.load('data/0_Agnes_100.wav', mono=True)\n",
        "mfcc = librosa.feature.mfcc(wave, sr)\n",
        "mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0)"
      ],
      "id": "OXlenB9BWTkk",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goiemkHoXGRL"
      },
      "source": [
        "model_input = np.array(mfcc)\n",
        "model_input = model_input.reshape(1, 20, 80)"
      ],
      "id": "goiemkHoXGRL",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLslc5YwXTGI"
      },
      "source": [
        "model_output = model.predict(model_input)"
      ],
      "id": "OLslc5YwXTGI",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltil0wc-YKUo",
        "outputId": "abf855fc-ab5d-44d6-f7e5-02d3ece43b7f"
      },
      "source": [
        "print(model_output)"
      ],
      "id": "Ltil0wc-YKUo",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.4227544e-01 7.5190297e-07 2.1749983e-02 6.5446432e-07 4.7448056e-04\n",
            "  7.7964836e-07 2.6274284e-02 2.7151461e-04 9.5497072e-02 8.7537402e-03\n",
            "  1.9678359e-03 6.7181670e-04 1.3139777e-05 8.5734029e-04 1.1910251e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIRuVGHJfIXn"
      },
      "source": [
        "pred = label_binarizer.inverse_transform(model_output)"
      ],
      "id": "QIRuVGHJfIXn",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWygZ9tGfzkj",
        "outputId": "466d2029-1c8b-413f-e4fa-9b5995b1a4b3"
      },
      "source": [
        "print(pred)"
      ],
      "id": "mWygZ9tGfzkj",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Agnes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPwrw1bFggPo"
      },
      "source": [
        "## Perform Recognition on Own Voice"
      ],
      "id": "LPwrw1bFggPo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnwY6crlgjp2"
      },
      "source": [
        "wave, sr = librosa.load('own_data/0_own.wav', mono=True)\n",
        "mfcc = librosa.feature.mfcc(wave, sr)\n",
        "# mfcc = np.pad(mfcc, ((0,0), (0, max_length-len(mfcc[0]))), mode='constant', constant_values=0)"
      ],
      "id": "jnwY6crlgjp2",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT5flaoMiv-i"
      },
      "source": [
        "model_input = np.array(mfcc)\n",
        "model_input = model_input.tolist()\n",
        "\n",
        "new_model_input = []\n",
        "\n",
        "for i in model_input:\n",
        "    new_model_input.append(i[:80])\n",
        "\n",
        "model_input = np.array(new_model_input)\n",
        "\n",
        "model_input = model_input.reshape(1, 20, 80)"
      ],
      "id": "lT5flaoMiv-i",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHOnyNSbqaEN"
      },
      "source": [
        "model_output = model.predict(model_input)"
      ],
      "id": "dHOnyNSbqaEN",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6ZH6x2aqstk",
        "outputId": "d9253783-2772-4dde-b8dc-499ea46dff11"
      },
      "source": [
        "print(model_output)"
      ],
      "id": "_6ZH6x2aqstk",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.4536329e-02 5.9525924e-08 2.0142584e-01 1.3455414e-05 6.8738249e-05\n",
            "  7.6857963e-05 1.6454317e-01 7.8974560e-02 5.0639375e-03 3.0583099e-03\n",
            "  6.0094148e-06 5.0554087e-04 1.4652185e-05 2.8091407e-01 1.8079846e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOXFnzsMquPi"
      },
      "source": [
        "pred = label_binarizer.inverse_transform(model_output)"
      ],
      "id": "aOXFnzsMquPi",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTH9ZTIAqv4W",
        "outputId": "9cb78d33-e4b1-4983-9c67-634af4e19be3"
      },
      "source": [
        "print(pred)"
      ],
      "id": "iTH9ZTIAqv4W",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Vicki']\n"
          ]
        }
      ]
    }
  ]
}